{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMAGE_FOLDER = \"./train/images/\"\n",
    "TRAIN_LABEL_FOLDER = \"./train/annotations/\"\n",
    "\n",
    "TEST_IMAGE_FOLDER = \"./test/images/\"\n",
    "TEST_LABEL_FOLDER = \"./test/annotations/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = []\n",
    "label_paths = []\n",
    "\n",
    "for file in os.listdir(TRAIN_IMAGE_FOLDER):\n",
    "    image_paths.append(os.path.join(TRAIN_IMAGE_FOLDER, file))\n",
    "\n",
    "for file in os.listdir(TRAIN_LABEL_FOLDER):\n",
    "    label_paths.append(os.path.join(TRAIN_LABEL_FOLDER, file))\n",
    "\n",
    "print(\"Number of images: \", len(image_paths))\n",
    "print(\"Number of labels: \", len(label_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "\n",
    "ground_truths = []\n",
    "keypoints_ground_truths = {}\n",
    "\n",
    "for path in tqdm(label_paths[50:]):\n",
    "    with open(path) as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    image_name = os.path.basename(path)[:-5] + \".jpg\"\n",
    "\n",
    "    for item in data[\"data-series\"]:\n",
    "        for k in item:\n",
    "            if isinstance(item[k], float):\n",
    "                item[k] = round(item[k], 4) \n",
    "\n",
    "    x_axis_ids = [item[\"id\"] for item in data[\"axes\"][\"x-axis\"][\"ticks\"]]\n",
    "    y_axis_ids = [item[\"id\"] for item in data[\"axes\"][\"y-axis\"][\"ticks\"]]\n",
    "\n",
    "    x_labels = [item for item in data[\"text\"] if item[\"id\"] in x_axis_ids]\n",
    "    x_labels.sort(key=lambda x: x[\"polygon\"][\"x0\"])\n",
    "    x_labels = [item[\"text\"].strip() for item in x_labels]\n",
    "\n",
    "    y_labels = [item for item in data[\"text\"] if item[\"id\"] in y_axis_ids]\n",
    "    y_labels.sort(key=lambda x: x[\"polygon\"][\"y0\"])\n",
    "    y_labels = [item[\"text\"].strip() for item in y_labels]\n",
    "\n",
    "    gt = {\n",
    "        \"file_name\": os.path.join(\"images\", image_name),\n",
    "        \"ground_truth\": {\n",
    "            \"gt_parse\": {\n",
    "                \"class\": data[\"chart-type\"],\n",
    "                \"value\": data[\"data-series\"],\n",
    "                \"x_type\": data[\"axes\"][\"x-axis\"][\"values-type\"],\n",
    "                \"y_type\": data[\"axes\"][\"y-axis\"][\"values-type\"],\n",
    "                \"x_labels\": x_labels,\n",
    "                \"y_labels\": y_labels,\n",
    "            }\n",
    "        },\n",
    "        \"source\": data[\"source\"],\n",
    "    }\n",
    "    ground_truths.append(gt)\n",
    "\n",
    "    # TODO: for multi stages pipeline, we need to save the points of each axis and the points of each data series\n",
    "    # we need to calculate pixel value of each point in data-series based on axis points\n",
    "    x_data = []\n",
    "    for tick in data[\"axes\"][\"x-axis\"][\"ticks\"]:\n",
    "        x_data.append(\n",
    "            {\n",
    "                \"id\": tick[\"id\"],\n",
    "                \"x\": tick[\"tick_pt\"][\"x\"],\n",
    "                \"y\": tick[\"tick_pt\"][\"y\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    y_data = []\n",
    "    for tick in data[\"axes\"][\"y-axis\"][\"ticks\"]:\n",
    "        y_data.append(\n",
    "            {\n",
    "                \"id\": tick[\"id\"],\n",
    "                \"x\": tick[\"tick_pt\"][\"x\"],\n",
    "                \"y\": tick[\"tick_pt\"][\"y\"],\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    # add label to x_data and y_data\n",
    "    x_id_to_text = {item[\"id\"]: item[\"text\"] for item in data[\"text\"] if item[\"id\"] in x_axis_ids}\n",
    "    y_id_to_text = {item[\"id\"]: item[\"text\"] for item in data[\"text\"] if item[\"id\"] in y_axis_ids}\n",
    "\n",
    "    for item in x_data:\n",
    "        item[\"text\"] = x_id_to_text[item[\"id\"]]\n",
    "    \n",
    "    for item in y_data:\n",
    "        item[\"text\"] = y_id_to_text[item[\"id\"]]\n",
    "\n",
    "    x_data_dict = {item[\"text\"]: item for item in x_data}\n",
    "    y_data_dict = {item[\"text\"]: item for item in y_data}\n",
    "\n",
    "    # calculate pixel values\n",
    "    x_type = data[\"axes\"][\"x-axis\"][\"values-type\"]\n",
    "    y_type = data[\"axes\"][\"y-axis\"][\"values-type\"]\n",
    "\n",
    "    skip = False\n",
    "    for item in data[\"data-series\"]:\n",
    "        try:\n",
    "            if x_type == \"numerical\":\n",
    "                x_value = float(item[\"x\"])\n",
    "                x_data.sort(key=lambda x: abs(float(x[\"text\"].replace(\",\", \"\").replace(\".\", \"\").replace(\"%\", \"\")) - x_value))\n",
    "                x1 = x_data[0]\n",
    "                x2 = x_data[1]\n",
    "                x1_value = float(x1[\"text\"].replace(\",\", \"\").replace(\".\", \"\").replace(\"%\", \"\"))\n",
    "                x2_value = float(x2[\"text\"].replace(\",\", \"\").replace(\".\", \"\").replace(\"%\", \"\"))\n",
    "                if x_value > float(x1[\"text\"]):\n",
    "                    x_pixel = (x_value - x1_value) / (x2_value - x1_value) * (x2[\"x\"] - x1[\"x\"]) + x1[\"x\"]\n",
    "                else:\n",
    "                    x_pixel = x1[\"x\"] - (x1_value - x_value) / (x2_value - x1_value) * (x2[\"x\"] - x1[\"x\"])\n",
    "            else: # categorical\n",
    "                x_value = item[\"x\"]\n",
    "                x_pixel = x_data_dict[x_value][\"x\"]\n",
    "            \n",
    "            if y_type == \"numerical\":\n",
    "                y_value = float(item[\"y\"])\n",
    "                y_data.sort(key=lambda x: abs(float(x[\"text\"].replace(\",\", \"\").replace(\".\", \"\").replace(\"%\", \"\")) - y_value))\n",
    "                y1 = y_data[0]\n",
    "                y2 = y_data[1]\n",
    "                y1_value = float(y1[\"text\"].replace(\",\", \"\").replace(\".\", \"\").replace(\"%\", \"\"))\n",
    "                y2_value = float(y2[\"text\"].replace(\",\", \"\").replace(\".\", \"\").replace(\"%\", \"\"))\n",
    "\n",
    "                if y_value > y1_value:\n",
    "                    y_pixel = (y_value - y1_value) / (y2_value - y1_value) * (y2[\"y\"] - y1[\"y\"]) + y1[\"y\"]\n",
    "                else:\n",
    "                    y_pixel = y1[\"y\"] - (y1_value - y_value) / (y2_value - y1_value) * (y2[\"y\"] - y1[\"y\"])\n",
    "            else: # categorical\n",
    "                y_value = item[\"y\"]\n",
    "                y_pixel = y_data_dict[y_value][\"y\"]\n",
    "\n",
    "            item[\"x_pixel\"] = x_pixel\n",
    "            item[\"y_pixel\"] = y_pixel\n",
    "\n",
    "        # DEBUG: plot data-series points to image\n",
    "        # image_path = os.path.join(TRAIN_IMAGE_FOLDER, image_name)\n",
    "        # image = cv2.imread(image_path)\n",
    "\n",
    "        # for item in data[\"data-series\"]:\n",
    "        #     cv2.circle(image, (int(item[\"x_pixel\"]), int(item[\"y_pixel\"])), 5, (0, 0, 255), -1)\n",
    "\n",
    "        # cv2.imwrite(os.path.join(\"debug\", image_name), image)\n",
    "        except:\n",
    "            skip = True\n",
    "            break\n",
    "\n",
    "    if not skip:\n",
    "        keypoints_ground_truths[image_name] = data[\"data-series\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure(figsize=(8, 6), dpi=80)\n",
    "\n",
    "# plt.imshow(image)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_item_from_source = {}\n",
    "for item in ground_truths:\n",
    "    if item[\"source\"] not in num_item_from_source:\n",
    "        num_item_from_source[item[\"source\"]] = 0\n",
    "    num_item_from_source[item[\"source\"]] += 1\n",
    "\n",
    "print(\"Number of items from each source: \", num_item_from_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item that has source = \"extracted\"\n",
    "source_image_paths = []\n",
    "for item in ground_truths:\n",
    "    if item[\"source\"] == \"extracted\":\n",
    "        source_image_paths.append(os.path.join(\"train\", item[\"file_name\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "Image.open(source_image_paths[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split ground truths into train and validation, validation images is all images from source = \"extracted\"\n",
    "train_ground_truths = []\n",
    "val_ground_truths = []\n",
    "\n",
    "for item in ground_truths:\n",
    "    if item[\"source\"] == \"extracted\":\n",
    "        val_ground_truths.append(item)\n",
    "    else:\n",
    "        train_ground_truths.append(item)\n",
    "\n",
    "print(\"Number of train ground truths: \", len(train_ground_truths))\n",
    "print(\"Number of val ground truths: \", len(val_ground_truths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_names = set([os.path.basename(item[\"file_name\"]) for item in train_ground_truths])\n",
    "val_file_names = set([os.path.basename(item[\"file_name\"]) for item in val_ground_truths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split keypoints ground truths into train and validation\n",
    "train_keypoints_ground_truths = {}\n",
    "val_keypoints_ground_truths = {}\n",
    "\n",
    "for image_name, keypoints in keypoints_ground_truths.items():\n",
    "    if image_name in train_file_names:\n",
    "        train_keypoints_ground_truths[image_name] = keypoints\n",
    "    elif image_name in val_file_names:\n",
    "        val_keypoints_ground_truths[image_name] = keypoints\n",
    "\n",
    "# save to json \n",
    "with open(\"train_keypoints_ground_truths.json\", \"w\") as f:\n",
    "    json.dump(train_keypoints_ground_truths, f)\n",
    "\n",
    "with open(\"val_keypoints_ground_truths.json\", \"w\") as f:\n",
    "    json.dump(val_keypoints_ground_truths, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy all images to train/images and val/images\n",
    "import shutil\n",
    "\n",
    "# make dirs for validation\n",
    "os.makedirs(\"./validation/images/\", exist_ok=True)\n",
    "\n",
    "for gt in tqdm(val_ground_truths):\n",
    "    shutil.copy2(os.path.join(\"./train\", gt[\"file_name\"]), \"./validation/images/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to jsonl file\n",
    "import jsonlines\n",
    "\n",
    "with jsonlines.open(\"./train/metadata.jsonl\", mode=\"w\") as writer:\n",
    "    writer.write_all(train_ground_truths)\n",
    "\n",
    "with jsonlines.open(\"./validation/metadata.jsonl\", mode=\"w\") as writer:\n",
    "    writer.write_all(val_ground_truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "lens = []\n",
    "\n",
    "for gt in ground_truths:\n",
    "    l = len(gt[\"ground_truth\"][\"gt_parse\"][\"value\"])\n",
    "    lens.append(l)\n",
    "    if l > max_len:\n",
    "        max_len = l\n",
    "\n",
    "print(\"Max number of data-series: \", max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw histogram of length of data-series\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(lens, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import Levenshtein as lev\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "def sigmoid2(x):\n",
    "    return 2 - 2 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    return np.sqrt(np.mean(np.square(y_true - y_pred)))\n",
    "\n",
    "\n",
    "def nrmse(y_true, y_pred):\n",
    "    if len(y_true) != len(y_pred):\n",
    "        return 0\n",
    "    # y_bar = np.array([np.mean(y_true) for _ in range(len(y_true))])\n",
    "    # return sigmoid2(rmse(y_true, y_pred) / rmse(y_true, y_bar))\n",
    "    return sigmoid2(1 - r2_score(y_true, y_pred))\n",
    "\n",
    "\n",
    "def nlev(y_true, y_pred):\n",
    "    if len(y_true) != len(y_pred):\n",
    "        return 0\n",
    "    return sigmoid2(sum([lev.distance(y_t, y_p) for y_t, y_p in zip(y_true, y_pred)]) / sum([len(y) for y in y_true]))\n",
    "\n",
    "\n",
    "def calculate_score(pred, gt):\n",
    "    if pred[\"class\"] != gt[\"class\"]:\n",
    "        return 0\n",
    "\n",
    "    if len(pred[\"value\"]) != len(gt[\"value\"]):\n",
    "        return 0\n",
    "    \n",
    "    if len(pred[\"value\"]) == 0 and len(gt[\"value\"]) == 0:\n",
    "        return 1\n",
    "\n",
    "    pred_xs = [x[\"x\"] for x in pred[\"value\"]]\n",
    "    pred_ys = [x[\"y\"] for x in pred[\"value\"]]\n",
    "\n",
    "    gt_xs = [x[\"x\"] for x in gt[\"value\"]]\n",
    "    gt_ys = [x[\"y\"] for x in gt[\"value\"]]\n",
    "\n",
    "    score = 0\n",
    "    if isinstance(gt_xs[0], str):\n",
    "        score += nlev(pred_xs, gt_xs)\n",
    "    else:\n",
    "        score += nrmse(pred_xs, gt_xs)\n",
    "\n",
    "    if isinstance(gt_ys[0], str):\n",
    "        score += nlev(pred_ys, gt_ys)\n",
    "    else:\n",
    "        score += nrmse(pred_ys, gt_ys)\n",
    "\n",
    "    return score / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_score(\n",
    "    {\n",
    "        'class': 'scatter',\n",
    "        'value': [\n",
    "            {'x': 1949.4201, 'y': 66.683},\n",
    "            {'x': 1954.6107, 'y': 66.2785},\n",
    "            {'x': 1959.9936, 'y': 65.6718},\n",
    "            {'x': 1964.7997, 'y': 64.0537},\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'class': 'scatter',\n",
    "        'value': [\n",
    "            {'x': 1949.4201, 'y': 6.683},\n",
    "            {'x': 1954.6107, 'y': 66.2785},\n",
    "            {'x': 1959.9936, 'y': 65.6718},\n",
    "            {'x': 1964.7997, 'y': 64.0537},\n",
    "        ]\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
