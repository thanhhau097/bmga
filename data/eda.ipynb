{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_IMAGE_FOLDER = \"./train/images/\"\n",
    "# TRAIN_LABEL_FOLDER = \"./train/annotations/\"\n",
    "\n",
    "# TEST_IMAGE_FOLDER = \"./test/images/\"\n",
    "# TEST_LABEL_FOLDER = \"./test/annotations/\"\n",
    "\n",
    "# ROOT_DATA_FOLDER = \"./external_data/all/\"\n",
    "# ROOT_DATA_FOLDER = \"./external_data/db/\"\n",
    "ROOT_DATA_FOLDER = \"./\"\n",
    "\n",
    "TRAIN_IMAGE_FOLDER = os.path.join(ROOT_DATA_FOLDER, \"train/images/\")\n",
    "TRAIN_LABEL_FOLDER = os.path.join(ROOT_DATA_FOLDER, \"train/annotations/\")\n",
    "\n",
    "TEST_IMAGE_FOLDER = os.path.join(ROOT_DATA_FOLDER, \"test/images/\")\n",
    "TEST_LABEL_FOLDER = os.path.join(ROOT_DATA_FOLDER, \"test/annotations/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = []\n",
    "label_paths = []\n",
    "\n",
    "for file in os.listdir(TRAIN_IMAGE_FOLDER):\n",
    "    image_paths.append(os.path.join(TRAIN_IMAGE_FOLDER, file))\n",
    "\n",
    "for file in os.listdir(TRAIN_LABEL_FOLDER):\n",
    "    label_paths.append(os.path.join(TRAIN_LABEL_FOLDER, file))\n",
    "\n",
    "print(\"Number of images: \", len(image_paths))\n",
    "print(\"Number of labels: \", len(label_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "\n",
    "ground_truths = []\n",
    "keypoints_ground_truths = {}\n",
    "text_detection_ground_truths = {}\n",
    "x_labels_text_detection_ground_truths = {}\n",
    "y_labels_text_detection_ground_truths = {}\n",
    "\n",
    "for path in tqdm(label_paths):\n",
    "    # if \"17000b60f53e\" not in path:\n",
    "    #     continue\n",
    "    with open(path) as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    if os.path.exists(os.path.join(TRAIN_IMAGE_FOLDER, os.path.basename(path)[:-5] + \".jpg\")):\n",
    "        image_name = os.path.basename(path)[:-5] + \".jpg\"\n",
    "    elif os.path.exists(os.path.join(TRAIN_IMAGE_FOLDER, os.path.basename(path)[:-5] + \".png\")):\n",
    "        image_name = os.path.basename(path)[:-5] + \".png\"\n",
    "    else:\n",
    "        print(\"Image not found: \", path)\n",
    "        continue\n",
    "\n",
    "    for item in data[\"data-series\"]:\n",
    "        for k in item:\n",
    "            if isinstance(item[k], float):\n",
    "                item[k] = round(item[k], 4) \n",
    "\n",
    "    x_axis_ids = [item[\"id\"] for item in data[\"axes\"][\"x-axis\"][\"ticks\"]]\n",
    "    y_axis_ids = [item[\"id\"] for item in data[\"axes\"][\"y-axis\"][\"ticks\"]]\n",
    "\n",
    "    x_labels = [item for item in data[\"text\"] if item[\"id\"] in x_axis_ids]\n",
    "    x_labels.sort(key=lambda x: x[\"polygon\"][\"x0\"])\n",
    "    x_labels = [item[\"text\"].strip() for item in x_labels]\n",
    "    x_labels_polygons = [item[\"polygon\"] for item in data[\"text\"] if item[\"id\"] in x_axis_ids]\n",
    "    x_labels_rects = []\n",
    "    for polygon in x_labels_polygons:\n",
    "        xs = [polygon[\"x0\"], polygon[\"x1\"], polygon[\"x2\"], polygon[\"x3\"]]\n",
    "        ys = [polygon[\"y0\"], polygon[\"y1\"], polygon[\"y2\"], polygon[\"y3\"]]\n",
    "\n",
    "        x_labels_rects.append([min(xs), min(ys), max(xs), max(ys)])\n",
    "\n",
    "    y_labels = [item for item in data[\"text\"] if item[\"id\"] in y_axis_ids]\n",
    "    y_labels.sort(key=lambda x: x[\"polygon\"][\"y0\"])\n",
    "    y_labels = [item[\"text\"].strip() for item in y_labels]\n",
    "    y_labels_polygons = [item[\"polygon\"] for item in data[\"text\"] if item[\"id\"] in y_axis_ids]\n",
    "    y_labels_rects = []\n",
    "    for polygon in y_labels_polygons:\n",
    "        xs = [polygon[\"x0\"], polygon[\"x1\"], polygon[\"x2\"], polygon[\"x3\"]]\n",
    "        ys = [polygon[\"y0\"], polygon[\"y1\"], polygon[\"y2\"], polygon[\"y3\"]]\n",
    "\n",
    "        y_labels_rects.append([min(xs), min(ys), max(xs), max(ys)])\n",
    "\n",
    "    gt = {\n",
    "        \"file_name\": os.path.join(\"images\", image_name),\n",
    "        \"ground_truth\": {\n",
    "            \"gt_parse\": {\n",
    "                \"class\": data[\"chart-type\"],\n",
    "                \"value\": data[\"data-series\"],\n",
    "                \"x_type\": data[\"axes\"][\"x-axis\"][\"values-type\"],\n",
    "                \"y_type\": data[\"axes\"][\"y-axis\"][\"values-type\"],\n",
    "                \"x_labels\": x_labels,\n",
    "                \"y_labels\": y_labels,\n",
    "                \"x_labels_polygons\": x_labels_polygons,\n",
    "                \"y_labels_polygons\": y_labels_polygons,\n",
    "                \"x_labels_rects\": x_labels_rects,\n",
    "                \"y_labels_rects\": y_labels_rects,\n",
    "            }\n",
    "        },\n",
    "        \"source\": data[\"source\"],\n",
    "    }\n",
    "    ground_truths.append(gt)\n",
    "\n",
    "    # TODO: for multi stages pipeline, we need to save the points of each axis and the points of each data series\n",
    "    # we need to calculate pixel value of each point in data-series based on axis points\n",
    "    x_data = []\n",
    "    for tick in data[\"axes\"][\"x-axis\"][\"ticks\"]:\n",
    "        x_data.append(\n",
    "            {\n",
    "                \"id\": tick[\"id\"],\n",
    "                \"x\": tick[\"tick_pt\"][\"x\"],\n",
    "                \"y\": tick[\"tick_pt\"][\"y\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    y_data = []\n",
    "    for tick in data[\"axes\"][\"y-axis\"][\"ticks\"]:\n",
    "        y_data.append(\n",
    "            {\n",
    "                \"id\": tick[\"id\"],\n",
    "                \"x\": tick[\"tick_pt\"][\"x\"],\n",
    "                \"y\": tick[\"tick_pt\"][\"y\"],\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    # add label to x_data and y_data\n",
    "    x_id_to_text = {item[\"id\"]: item[\"text\"] for item in data[\"text\"] if item[\"id\"] in x_axis_ids}\n",
    "    y_id_to_text = {item[\"id\"]: item[\"text\"] for item in data[\"text\"] if item[\"id\"] in y_axis_ids}\n",
    "\n",
    "    for item in x_data:\n",
    "        item[\"text\"] = x_id_to_text[item[\"id\"]]\n",
    "    \n",
    "    for item in y_data:\n",
    "        item[\"text\"] = y_id_to_text[item[\"id\"]]\n",
    "\n",
    "    # x_data_dict = {item[\"text\"]: item for item in x_data}\n",
    "    # y_data_dict = {item[\"text\"]: item for item in y_data}\n",
    "    from collections import defaultdict\n",
    "    x_data_dict = defaultdict(list)\n",
    "    for item in x_data:\n",
    "        x_data_dict[item[\"text\"]].append(item)\n",
    "    \n",
    "    y_data_dict = defaultdict(list)\n",
    "    for item in y_data:\n",
    "        y_data_dict[item[\"text\"]].append(item)\n",
    "\n",
    "    # calculate pixel values\n",
    "    x_type = data[\"axes\"][\"x-axis\"][\"values-type\"]\n",
    "    y_type = data[\"axes\"][\"y-axis\"][\"values-type\"]\n",
    "\n",
    "    skip = False\n",
    "    for item in data[\"data-series\"]:\n",
    "        try:\n",
    "            if x_type == \"numerical\":\n",
    "                x_value = float(item[\"x\"])\n",
    "                x_data.sort(key=lambda x: abs(float(x[\"text\"].replace(\",\", \".\").replace(\"%\", \"\")) - x_value))\n",
    "                x1 = x_data[0]\n",
    "                x2 = x_data[1]\n",
    "                x1_value = float(x1[\"text\"].replace(\",\", \".\").replace(\"%\", \"\"))\n",
    "                x2_value = float(x2[\"text\"].replace(\",\", \".\").replace(\"%\", \"\"))\n",
    "\n",
    "                # print(\"x_value: \", x_value, \"x1_value: \", x1_value, \"x2_value: \", x2_value, \"x1: \", x1, \"x2: \", x2)\n",
    "                # TODO: check this, make it similar to pipeline.ipynb\n",
    "                if x_value > float(x1[\"text\"]):\n",
    "                    x_pixel = (x_value - x1_value) / (x2_value - x1_value) * (x2[\"x\"] - x1[\"x\"]) + x1[\"x\"]\n",
    "                else:\n",
    "                    x_pixel = x1[\"x\"] - (x1_value - x_value) / (x2_value - x1_value) * (x2[\"x\"] - x1[\"x\"])\n",
    "            else: # categorical\n",
    "                x_value = item[\"x\"]\n",
    "                x_pixel = x_data_dict[x_value].pop(0)[\"x\"]\n",
    "                # print(x_value)\n",
    "            \n",
    "            if y_type == \"numerical\":\n",
    "                y_value = float(item[\"y\"])\n",
    "                y_data.sort(key=lambda x: abs(float(x[\"text\"].replace(\",\", \".\").replace(\"%\", \"\")) - y_value))\n",
    "                y1 = y_data[0]\n",
    "                y2 = y_data[1]\n",
    "                y1_value = float(y1[\"text\"].replace(\",\", \"\").replace(\"%\", \"\"))\n",
    "                y2_value = float(y2[\"text\"].replace(\",\", \"\").replace(\"%\", \"\"))\n",
    "\n",
    "                # print(\"y_value =\", y_value, \"y1_value =\", y1_value, \"y2_value =\", y2_value, \"y1[y] =\", y1[\"y\"], \"y2[y] =\", y2[\"y\"])\n",
    "                # TODO: check this, make it similar to pipeline.ipynb\n",
    "                if y_value > y1_value:\n",
    "                    y_pixel = (y_value - y1_value) / (y2_value - y1_value) * (y2[\"y\"] - y1[\"y\"]) + y1[\"y\"]\n",
    "                else:\n",
    "                    y_pixel = y1[\"y\"] - (y1_value - y_value) / (y2_value - y1_value) * (y2[\"y\"] - y1[\"y\"])\n",
    "            else: # categorical\n",
    "                y_value = item[\"y\"]\n",
    "                y_pixel = y_data_dict[y_value].pop(0)[\"y\"]\n",
    "\n",
    "            item[\"x_pixel\"] = x_pixel\n",
    "            item[\"y_pixel\"] = y_pixel\n",
    "        except:\n",
    "            skip = True\n",
    "            break\n",
    "    # # DEBUG: plot data-series points to image\n",
    "    # image_path = os.path.join(TRAIN_IMAGE_FOLDER, image_name)\n",
    "    # image = cv2.imread(image_path)\n",
    "\n",
    "    # for item in data[\"data-series\"]:\n",
    "    #     cv2.circle(image, (int(item[\"x_pixel\"]), int(item[\"y_pixel\"])), 5, (0, 0, 255), -1)\n",
    "\n",
    "    # # cv2.imwrite(os.path.join(\"debug\", image_name), image)\n",
    "    # plt.imshow(image)\n",
    "    # plt.show()\n",
    "    # break\n",
    "\n",
    "\n",
    "    if not skip:\n",
    "        keypoints_ground_truths[image_name] = {\n",
    "            \"value\": data[\"data-series\"],\n",
    "            \"x\": data[\"axes\"][\"x-axis\"][\"ticks\"],\n",
    "            \"y\": data[\"axes\"][\"y-axis\"][\"ticks\"],\n",
    "            \"x_label\": x_labels_rects,\n",
    "            \"y_label\": y_labels_rects,\n",
    "            \"chart_type\": data[\"chart-type\"],\n",
    "        }\n",
    "\n",
    "    # prepare polygon ground truth\n",
    "    polygon_text = \"\"\n",
    "    for item in data[\"text\"]:\n",
    "        x0 = item[\"polygon\"][\"x0\"]\n",
    "        y0 = item[\"polygon\"][\"y0\"]\n",
    "        x1 = item[\"polygon\"][\"x1\"]\n",
    "        y1 = item[\"polygon\"][\"y1\"]\n",
    "        x2 = item[\"polygon\"][\"x2\"]\n",
    "        y2 = item[\"polygon\"][\"y2\"]\n",
    "        x3 = item[\"polygon\"][\"x3\"]\n",
    "        y3 = item[\"polygon\"][\"y3\"]\n",
    "        polygon_text += f\"{x0},{y0},{x1},{y1},{x2},{y2},{x3},{y3},dummy_text\\n\"\n",
    "\n",
    "    if data[\"chart-type\"] == \"horizontal_bar\" and os.path.basename(path).startswith(\"PMC\"): # chartinfo data\n",
    "        x_axis_ids, y_axis_ids = y_axis_ids, x_axis_ids\n",
    "    x_labels_poly_text = \"\"\n",
    "    for item in data[\"text\"]:\n",
    "        if item[\"id\"] in x_axis_ids:\n",
    "            x0 = item[\"polygon\"][\"x0\"]\n",
    "            y0 = item[\"polygon\"][\"y0\"]\n",
    "            x1 = item[\"polygon\"][\"x1\"]\n",
    "            y1 = item[\"polygon\"][\"y1\"]\n",
    "            x2 = item[\"polygon\"][\"x2\"]\n",
    "            y2 = item[\"polygon\"][\"y2\"]\n",
    "            x3 = item[\"polygon\"][\"x3\"]\n",
    "            y3 = item[\"polygon\"][\"y3\"]\n",
    "            x_labels_poly_text += f\"{x0},{y0},{x1},{y1},{x2},{y2},{x3},{y3},dummy_text\\n\"\n",
    "\n",
    "    y_labels_poly_text = \"\"\n",
    "    for item in data[\"text\"]:\n",
    "        if item[\"id\"] in y_axis_ids:\n",
    "            x0 = item[\"polygon\"][\"x0\"]\n",
    "            y0 = item[\"polygon\"][\"y0\"]\n",
    "            x1 = item[\"polygon\"][\"x1\"]\n",
    "            y1 = item[\"polygon\"][\"y1\"]\n",
    "            x2 = item[\"polygon\"][\"x2\"]\n",
    "            y2 = item[\"polygon\"][\"y2\"]\n",
    "            x3 = item[\"polygon\"][\"x3\"]\n",
    "            y3 = item[\"polygon\"][\"y3\"]\n",
    "            y_labels_poly_text += f\"{x0},{y0},{x1},{y1},{x2},{y2},{x3},{y3},dummy_text\\n\"\n",
    "\n",
    "\n",
    "    text_detection_ground_truths[image_name] = polygon_text\n",
    "    x_labels_text_detection_ground_truths[image_name] = x_labels_poly_text\n",
    "    y_labels_text_detection_ground_truths[image_name] = y_labels_poly_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize text_detection_ground_truths\n",
    "import numpy as np\n",
    "# shuffle\n",
    "x_labels_text_detection_ground_truths = {k: x_labels_text_detection_ground_truths[k] for k in np.random.permutation(list(x_labels_text_detection_ground_truths.keys()))}\n",
    "for image_name, polygon_text in x_labels_text_detection_ground_truths.items():\n",
    "    image_path = os.path.join(TRAIN_IMAGE_FOLDER, image_name)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    for line in polygon_text.splitlines():\n",
    "        points = line.split(\",dummy_text\")[0].split(\",\")\n",
    "        points = [int(x) for x in points]\n",
    "        points = np.array(points).reshape(-1, 2)\n",
    "        cv2.polylines(image, [points], True, (0, 255, 0), 2)\n",
    "\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure(figsize=(8, 6), dpi=80)\n",
    "\n",
    "# plt.imshow(image)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_item_from_source = {}\n",
    "for item in ground_truths:\n",
    "    if item[\"source\"] not in num_item_from_source:\n",
    "        num_item_from_source[item[\"source\"]] = 0\n",
    "    num_item_from_source[item[\"source\"]] += 1\n",
    "\n",
    "print(\"Number of items from each source: \", num_item_from_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item that has source = \"extracted\"\n",
    "source_image_paths = []\n",
    "for item in ground_truths:\n",
    "    if item[\"source\"] == \"extracted\":\n",
    "        source_image_paths.append(os.path.join(\"train\", item[\"file_name\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "Image.open(source_image_paths[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train and validation image paths from train_list.txt and val_list.txt\n",
    "train_image_paths = []\n",
    "val_image_paths = []\n",
    "\n",
    "all_image_paths = []\n",
    "for item in ground_truths:\n",
    "    all_image_paths.append(os.path.basename(item[\"file_name\"]))\n",
    "\n",
    "# with open(\"train_list.txt\", \"r\") as f:\n",
    "#     for line in f:\n",
    "#         train_image_paths.append(line.strip())\n",
    "\n",
    "with open(\"val_list.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        val_image_paths.append(line.strip())\n",
    "\n",
    "\n",
    "# remaining is train_image_paths\n",
    "train_image_paths = list(set(all_image_paths) - set(val_image_paths))\n",
    "\n",
    "print(\"Number of train images: \", len(train_image_paths))\n",
    "print(\"Number of val images: \", len(val_image_paths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split ground truth based on this train and validation image paths\n",
    "train_ground_truths = []\n",
    "val_ground_truths = []\n",
    "\n",
    "set_train_image_paths = set(train_image_paths)\n",
    "set_val_image_paths = set(val_image_paths)\n",
    "\n",
    "for item in tqdm(ground_truths):\n",
    "    image_path = os.path.basename(item[\"file_name\"])\n",
    "    if image_path in set_train_image_paths:\n",
    "        train_ground_truths.append(item)\n",
    "    elif image_path in set_val_image_paths:\n",
    "        val_ground_truths.append(item)\n",
    "    else:\n",
    "        raise Exception(\"Image path not found in train_list.txt or val_list.txt\", image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split ground truths into train and validation, validation images is all images from source = \"extracted\"\n",
    "# train_ground_truths = []\n",
    "# val_ground_truths = []\n",
    "\n",
    "# for item in ground_truths:\n",
    "#     if item[\"source\"] != \"extracted\":\n",
    "#         train_ground_truths.append(item)\n",
    "\n",
    "# # split 50:50 extracted source images into train and validation\n",
    "# remain_ground_truths = []\n",
    "# for item in ground_truths:\n",
    "#     if item[\"source\"] == \"extracted\":\n",
    "#         remain_ground_truths.append(item)\n",
    "\n",
    "# # set seed for reproducibility\n",
    "# import random\n",
    "# random.seed(42)\n",
    "# random.shuffle(remain_ground_truths)\n",
    "\n",
    "# for i in range(len(remain_ground_truths)):\n",
    "#     if i < len(remain_ground_truths) // 2:\n",
    "#         train_ground_truths.append(remain_ground_truths[i])\n",
    "#     else:\n",
    "#         val_ground_truths.append(remain_ground_truths[i])\n",
    "\n",
    "# print(\"Number of train ground truths: \", len(train_ground_truths))\n",
    "# print(\"Number of val ground truths: \", len(val_ground_truths))\n",
    "\n",
    "# # print one example\n",
    "# print(val_ground_truths[0][\"ground_truth\"][\"gt_parse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_names = set([os.path.basename(item[\"file_name\"]) for item in train_ground_truths])\n",
    "val_file_names = set([os.path.basename(item[\"file_name\"]) for item in val_ground_truths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split keypoints ground truths into train and validation\n",
    "train_keypoints_ground_truths = {}\n",
    "val_keypoints_ground_truths = {}\n",
    "\n",
    "for image_name, keypoints in keypoints_ground_truths.items():\n",
    "    if image_name in train_file_names:\n",
    "        train_keypoints_ground_truths[image_name] = keypoints\n",
    "    elif image_name in val_file_names:\n",
    "        val_keypoints_ground_truths[image_name] = keypoints\n",
    "\n",
    "# # save to json \n",
    "# with open(os.path.join(ROOT_DATA_FOLDER, \"train_keypoints_ground_truths.json\"), \"w\") as f:\n",
    "#     json.dump(train_keypoints_ground_truths, f)\n",
    "\n",
    "# with open(os.path.join(ROOT_DATA_FOLDER, \"val_keypoints_ground_truths.json\"), \"w\") as f:\n",
    "#     json.dump(val_keypoints_ground_truths, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy all images to train/images and val/images\n",
    "import shutil\n",
    "\n",
    "# make dirs for validation\n",
    "os.makedirs(os.path.join(ROOT_DATA_FOLDER, \"validation/images/\"), exist_ok=True)\n",
    "\n",
    "for gt in tqdm(val_ground_truths):\n",
    "    shutil.copy2(os.path.join(ROOT_DATA_FOLDER, \"train\", gt[\"file_name\"]), os.path.join(ROOT_DATA_FOLDER, \"validation/images/\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to jsonl file\n",
    "import jsonlines\n",
    "\n",
    "with jsonlines.open(os.path.join(ROOT_DATA_FOLDER, \"train/metadata.jsonl\"), mode=\"w\") as writer:\n",
    "    writer.write_all(train_ground_truths)\n",
    "\n",
    "with jsonlines.open(os.path.join(ROOT_DATA_FOLDER, \"validation/metadata.jsonl\"), mode=\"w\") as writer:\n",
    "    writer.write_all(val_ground_truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary\n",
    "text_gts = y_labels_text_detection_ground_truths\n",
    "\n",
    "val_image_names = os.listdir(os.path.join(ROOT_DATA_FOLDER, \"validation/images\"))\n",
    "train_image_names = set(text_gts.keys()) - set(val_image_names)\n",
    "\n",
    "print(\"train_image_names: \", len(train_image_names))\n",
    "print(\"val_image_names: \", len(val_image_names))\n",
    "\n",
    "TRAIN_TEXT_DETECTION_FOLDER = os.path.join(ROOT_DATA_FOLDER, \"y_labels_train_gts\")\n",
    "VAL_TEXT_DETECTION_FOLDER = os.path.join(ROOT_DATA_FOLDER, \"y_labels_val_gts\")\n",
    "\n",
    "# makedirs\n",
    "os.makedirs(TRAIN_TEXT_DETECTION_FOLDER, exist_ok=True)\n",
    "os.makedirs(VAL_TEXT_DETECTION_FOLDER, exist_ok=True)\n",
    "\n",
    "for image_name, text in tqdm(text_gts.items()):\n",
    "    if image_name in train_image_names:\n",
    "        with open(os.path.join(TRAIN_TEXT_DETECTION_FOLDER, image_name + \".txt\"), \"w\") as f:\n",
    "            f.write(text)\n",
    "    else:\n",
    "        with open(os.path.join(VAL_TEXT_DETECTION_FOLDER, image_name + \".txt\"), \"w\") as f:\n",
    "            f.write(text)\n",
    "\n",
    "# train_list.txt and val_list.txt\n",
    "with open(os.path.join(ROOT_DATA_FOLDER, \"y_labels_train_list.txt\"), \"w\") as f:\n",
    "    for image_name in train_image_names:\n",
    "        f.write(image_name + \"\\n\")\n",
    "\n",
    "with open(os.path.join(ROOT_DATA_FOLDER, \"y_labels_val_list.txt\"), \"w\") as f:\n",
    "    for image_name in val_image_names:\n",
    "        f.write(image_name + \"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary\n",
    "text_gts = x_labels_text_detection_ground_truths\n",
    "\n",
    "val_image_names = os.listdir(os.path.join(ROOT_DATA_FOLDER, \"validation/images\"))\n",
    "train_image_names = set(text_gts.keys()) - set(val_image_names)\n",
    "\n",
    "print(\"train_image_names: \", len(train_image_names))\n",
    "print(\"val_image_names: \", len(val_image_names))\n",
    "\n",
    "TRAIN_TEXT_DETECTION_FOLDER = os.path.join(ROOT_DATA_FOLDER, \"x_labels_train_gts\")\n",
    "VAL_TEXT_DETECTION_FOLDER = os.path.join(ROOT_DATA_FOLDER, \"x_labels_val_gts\")\n",
    "\n",
    "# makedirs\n",
    "os.makedirs(TRAIN_TEXT_DETECTION_FOLDER, exist_ok=True)\n",
    "os.makedirs(VAL_TEXT_DETECTION_FOLDER, exist_ok=True)\n",
    "\n",
    "for image_name, text in tqdm(text_gts.items()):\n",
    "    if image_name in train_image_names:\n",
    "        with open(os.path.join(TRAIN_TEXT_DETECTION_FOLDER, image_name + \".txt\"), \"w\") as f:\n",
    "            f.write(text)\n",
    "    else:\n",
    "        with open(os.path.join(VAL_TEXT_DETECTION_FOLDER, image_name + \".txt\"), \"w\") as f:\n",
    "            f.write(text)\n",
    "\n",
    "# train_list.txt and val_list.txt\n",
    "with open(os.path.join(ROOT_DATA_FOLDER, \"x_labels_train_list.txt\"), \"w\") as f:\n",
    "    for image_name in train_image_names:\n",
    "        f.write(image_name + \"\\n\")\n",
    "\n",
    "with open(os.path.join(ROOT_DATA_FOLDER, \"x_labels_val_list.txt\"), \"w\") as f:\n",
    "    for image_name in val_image_names:\n",
    "        f.write(image_name + \"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "lens = []\n",
    "\n",
    "for gt in ground_truths:\n",
    "    l = len(gt[\"ground_truth\"][\"gt_parse\"][\"value\"])\n",
    "    lens.append(l)\n",
    "    if l > max_len:\n",
    "        max_len = l\n",
    "\n",
    "print(\"Max number of data-series: \", max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw histogram of length of data-series\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(lens, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import Levenshtein as lev\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "def sigmoid2(x):\n",
    "    return 2 - 2 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    return np.sqrt(np.mean(np.square(y_true - y_pred)))\n",
    "\n",
    "\n",
    "def nrmse(y_true, y_pred):\n",
    "    if len(y_true) != len(y_pred):\n",
    "        return 0\n",
    "    # y_bar = np.array([np.mean(y_true) for _ in range(len(y_true))])\n",
    "    # return sigmoid2(rmse(y_true, y_pred) / rmse(y_true, y_bar))\n",
    "    return sigmoid2(1 - r2_score(y_true, y_pred))\n",
    "\n",
    "\n",
    "def nlev(y_true, y_pred):\n",
    "    if len(y_true) != len(y_pred):\n",
    "        return 0\n",
    "    return sigmoid2(sum([lev.distance(y_t, y_p) for y_t, y_p in zip(y_true, y_pred)]) / sum([len(y) for y in y_true]))\n",
    "\n",
    "\n",
    "def calculate_score(pred, gt):\n",
    "    if pred[\"class\"] != gt[\"class\"]:\n",
    "        return 0\n",
    "\n",
    "    if len(pred[\"value\"]) != len(gt[\"value\"]):\n",
    "        return 0\n",
    "    \n",
    "    if len(pred[\"value\"]) == 0 and len(gt[\"value\"]) == 0:\n",
    "        return 1\n",
    "\n",
    "    pred_xs = [x[\"x\"] for x in pred[\"value\"]]\n",
    "    pred_ys = [x[\"y\"] for x in pred[\"value\"]]\n",
    "\n",
    "    gt_xs = [x[\"x\"] for x in gt[\"value\"]]\n",
    "    gt_ys = [x[\"y\"] for x in gt[\"value\"]]\n",
    "\n",
    "    score = 0\n",
    "    if isinstance(gt_xs[0], str):\n",
    "        score += nlev(pred_xs, gt_xs)\n",
    "    else:\n",
    "        score += nrmse(pred_xs, gt_xs)\n",
    "\n",
    "    if isinstance(gt_ys[0], str):\n",
    "        score += nlev(pred_ys, gt_ys)\n",
    "    else:\n",
    "        score += nrmse(pred_ys, gt_ys)\n",
    "\n",
    "    return score / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_score(\n",
    "    {\n",
    "        'class': 'scatter',\n",
    "        'value': [\n",
    "            {'x': 1949.4201, 'y': 66.683},\n",
    "            {'x': 1954.6107, 'y': 66.2785},\n",
    "            {'x': 1959.9936, 'y': 65.6718},\n",
    "            {'x': 1964.7997, 'y': 64.0537},\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'class': 'scatter',\n",
    "        'value': [\n",
    "            {'x': 1949.4201, 'y': 6.683},\n",
    "            {'x': 1954.6107, 'y': 66.2785},\n",
    "            {'x': 1959.9936, 'y': 65.6718},\n",
    "            {'x': 1964.7997, 'y': 64.0537},\n",
    "        ]\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare YoloX data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list of x, y pairs to coco format\n",
    "def convert_keypoints_data_to_coco_format(gts, folder=\"train\", chart_types=[], available_classes=[\"value\", \"x\", \"y\"], box_size=12):\n",
    "    images = []\n",
    "    annotations = []\n",
    "\n",
    "    classes = [\"value\", \"x\", \"y\", \"x_label\", \"y_label\"]\n",
    "\n",
    "    i = 0\n",
    "    for _, (k, v) in tqdm(enumerate(gts.items())):\n",
    "        if chart_types and v[\"chart_type\"] not in chart_types:\n",
    "            continue\n",
    "\n",
    "        path = os.path.join(ROOT_DATA_FOLDER, f\"./{folder}/images/\", k)\n",
    "        img = cv2.imread(path)\n",
    "        images.append({\n",
    "            \"id\": i,\n",
    "            \"file_name\": k,\n",
    "            \"width\": img.shape[1],\n",
    "            \"height\": img.shape[0],\n",
    "        })\n",
    "\n",
    "        size = box_size\n",
    "        box_height = box_width = min(int(size / 640 * img.shape[0]), int(size / 640 * img.shape[1]))\n",
    "\n",
    "        for c in classes:\n",
    "            if c not in available_classes:\n",
    "                continue\n",
    "            if c == \"value\":\n",
    "                for j, point in enumerate(v[c]):\n",
    "                    bbox = [point[\"x_pixel\"] - box_width // 2, point[\"y_pixel\"] - box_height // 2, box_width, box_height]\n",
    "                    annotations.append({\n",
    "                        \"id\": len(annotations),\n",
    "                        \"image_id\": i,\n",
    "                        \"category_id\": 1,\n",
    "                        \"bbox\": bbox,\n",
    "                        \"iscrowd\": 0,\n",
    "                        \"area\": 100,\n",
    "                    })\n",
    "            elif c in [\"x\", \"y\"]:\n",
    "                for j, point in enumerate(v[c]):\n",
    "                    bbox = [point[\"tick_pt\"][\"x\"] - box_width // 2, point[\"tick_pt\"][\"y\"] - box_height // 2, box_width, box_height]\n",
    "                    annotations.append({\n",
    "                        \"id\": len(annotations),\n",
    "                        \"image_id\": i,\n",
    "                        \"category_id\": 2 if c == \"x\" else 3,\n",
    "                        \"bbox\": bbox,\n",
    "                        \"iscrowd\": 0,\n",
    "                        \"area\": 100,\n",
    "                    })\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    coco_annotations = {\n",
    "        \"images\": images,\n",
    "        \"annotations\": annotations,\n",
    "        \"categories\": [\n",
    "            {\n",
    "                \"id\": 1,\n",
    "                \"name\": \"value\",\n",
    "                \"supercategory\": \"value\",\n",
    "            },\n",
    "            {\n",
    "                \"id\": 2,\n",
    "                \"name\": \"x\",\n",
    "                \"supercategory\": \"x\",\n",
    "            },\n",
    "            {\n",
    "                \"id\": 3,\n",
    "                \"name\": \"y\",\n",
    "                \"supercategory\": \"y\",\n",
    "            },\n",
    "        ],\n",
    "        \"type\": \"instances\",\n",
    "    }\n",
    "\n",
    "    return coco_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert to coco format\n",
    "# train_coco_annotations = convert_keypoints_data_to_coco_format(train_keypoints_ground_truths, box_size=24)\n",
    "# val_coco_annotations = convert_keypoints_data_to_coco_format(val_keypoints_ground_truths, box_size=24)\n",
    "\n",
    "# annotation_folder_name = \"annotations_all\"\n",
    "\n",
    "# if not os.path.exists(os.path.join(ROOT_DATA_FOLDER, annotation_folder_name)):\n",
    "#     os.makedirs(os.path.join(ROOT_DATA_FOLDER, annotation_folder_name))\n",
    "\n",
    "# # save to json\n",
    "# with open(os.path.join(ROOT_DATA_FOLDER, f\"{annotation_folder_name}/train_coco_annotations.json\"), \"w\") as writer:\n",
    "#     json.dump(train_coco_annotations, writer)\n",
    "\n",
    "# with open(os.path.join(ROOT_DATA_FOLDER, f\"{annotation_folder_name}/val_coco_annotations.json\"), \"w\") as writer:\n",
    "#     json.dump(val_coco_annotations, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_coco_annotations = convert_keypoints_data_to_coco_format(train_keypoints_ground_truths, chart_types=[], available_classes=[\"x\", \"y\"], box_size=24)\n",
    "val_coco_annotations = convert_keypoints_data_to_coco_format(val_keypoints_ground_truths, chart_types=[], available_classes=[\"x\", \"y\"], box_size=24)\n",
    "\n",
    "annotation_folder_name = \"annotations_xy\"\n",
    "\n",
    "if not os.path.exists(os.path.join(ROOT_DATA_FOLDER, annotation_folder_name)):\n",
    "    os.makedirs(os.path.join(ROOT_DATA_FOLDER, annotation_folder_name))\n",
    "\n",
    "# save to json\n",
    "with open(os.path.join(ROOT_DATA_FOLDER, f\"{annotation_folder_name}/train_coco_annotations.json\"), \"w\") as writer:\n",
    "    json.dump(train_coco_annotations, writer)\n",
    "\n",
    "with open(os.path.join(ROOT_DATA_FOLDER, f\"{annotation_folder_name}/val_coco_annotations.json\"), \"w\") as writer:\n",
    "    json.dump(val_coco_annotations, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chart_types in [\n",
    "    [\"scatter\"],\n",
    "    [\"line\"],\n",
    "    [\"horizontal_bar\", \"vertical_bar\", \"dot\"]\n",
    "]:\n",
    "\n",
    "    if chart_types == [\"scatter\"]:\n",
    "        annotation_folder_name = \"annotations_scatter_value\"\n",
    "        box_size = 12\n",
    "    elif chart_types == [\"line\"]:\n",
    "        annotation_folder_name = \"annotations_line_value\"\n",
    "        box_size = 12\n",
    "    else:\n",
    "        annotation_folder_name = \"annotations_bar_value\"\n",
    "        box_size = 24\n",
    "\n",
    "    train_coco_annotations = convert_keypoints_data_to_coco_format(train_keypoints_ground_truths, chart_types=chart_types, available_classes=[\"value\"], box_size=box_size)\n",
    "    val_coco_annotations = convert_keypoints_data_to_coco_format(val_keypoints_ground_truths, chart_types=chart_types, available_classes=[\"value\"], box_size=box_size)\n",
    "\n",
    "    if not os.path.exists(os.path.join(ROOT_DATA_FOLDER, annotation_folder_name)):\n",
    "        os.makedirs(os.path.join(ROOT_DATA_FOLDER, annotation_folder_name))\n",
    "\n",
    "    # save to json\n",
    "    with open(os.path.join(ROOT_DATA_FOLDER, f\"{annotation_folder_name}/train_coco_annotations.json\"), \"w\") as writer:\n",
    "        json.dump(train_coco_annotations, writer)\n",
    "\n",
    "    with open(os.path.join(ROOT_DATA_FOLDER, f\"{annotation_folder_name}/val_coco_annotations.json\"), \"w\") as writer:\n",
    "        json.dump(val_coco_annotations, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "ROOT_DATA_FOLDER = \"./\"\n",
    "annotation_folder_name = \"annotations_xy\"\n",
    "\n",
    "\n",
    "with open(os.path.join(ROOT_DATA_FOLDER, f\"{annotation_folder_name}/train_coco_annotations.json\"), \"r\") as writer:\n",
    "    train_coco_annotations = json.load(writer)\n",
    "\n",
    "with open(os.path.join(ROOT_DATA_FOLDER, f\"{annotation_folder_name}/val_coco_annotations.json\"), \"r\") as writer:\n",
    "    val_coco_annotations = json.load(writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize one image with coco annotations to check if everything is correct\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "def visualize_coco_annotations(coco_annotations, image_id):\n",
    "    coco = COCO()\n",
    "    coco.dataset = coco_annotations\n",
    "    coco.createIndex()\n",
    "\n",
    "    img = coco.loadImgs(image_id)[0]\n",
    "    I = cv2.imread(os.path.join(ROOT_DATA_FOLDER, \"train/images/\", img[\"file_name\"]))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(I)\n",
    "\n",
    "    annIds = coco.getAnnIds(imgIds=img[\"id\"])\n",
    "    anns = coco.loadAnns(annIds)\n",
    "\n",
    "    for ann in anns:\n",
    "        bbox = ann[\"bbox\"]\n",
    "        # different colors for different classes\n",
    "        if ann[\"category_id\"] == 1:\n",
    "            rect = patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], linewidth=1, edgecolor=\"r\", facecolor=\"none\")\n",
    "        elif ann[\"category_id\"] == 2:\n",
    "            rect = patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], linewidth=1, edgecolor=\"g\", facecolor=\"none\")\n",
    "        elif ann[\"category_id\"] == 3:\n",
    "            rect = patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], linewidth=1, edgecolor=\"b\", facecolor=\"none\")\n",
    "        elif ann[\"category_id\"] == 4:\n",
    "            rect = patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], linewidth=1, edgecolor=\"y\", facecolor=\"none\")\n",
    "        elif ann[\"category_id\"] == 5:\n",
    "            rect = patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], linewidth=1, edgecolor=\"c\", facecolor=\"none\")\n",
    "        plt.gca().add_patch(rect)\n",
    "    \n",
    "    # increase size of image\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(10, 8)\n",
    "    plt.show()\n",
    "\n",
    "index = random.randint(0, len(train_coco_annotations[\"images\"]))\n",
    "visualize_coco_annotations(train_coco_annotations, index)\n",
    "\n",
    "print(train_coco_annotations[\"images\"][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_coco_annotations[\"images\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_coco_annotations[\"images\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # wrong data: 374fcc8c9542.jpg, a80688cb2101.jpg, b9507ab4e9fc.jpg, 3d0b1f8e6f61.jpg, 907a4cbc9ff1.jpg, fbf4820dc2c1.jpg\n",
    "\n",
    "# image_name = \"374fcc8c9542.jpg\"\n",
    "# points = train_keypoints_ground_truths[image_name][\"value\"]\n",
    "\n",
    "# # visualize \n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.patches as patches\n",
    "\n",
    "# def visualize_points(img, points):\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.imshow(img)\n",
    "\n",
    "#     for point in points:\n",
    "#         rect = patches.Rectangle((point[\"x_pixel\"] - 5, point[\"y_pixel\"] - 5), 10, 10, linewidth=1, edgecolor=\"r\", facecolor=\"none\")\n",
    "#         plt.gca().add_patch(rect)\n",
    "    \n",
    "#     # increase size of image\n",
    "#     fig = plt.gcf()\n",
    "#     fig.set_size_inches(18.5, 10.5)\n",
    "#     plt.show()\n",
    "\n",
    "# img = cv2.imread(os.path.join(\"./train/images/\", image_name))\n",
    "# visualize_points(img, points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# External data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy all original data to new folder\n",
    "import shutil\n",
    "\n",
    "task = \"db\"\n",
    "\n",
    "TARGET_IMAGE_FOLDER = f\"/home/thanh/bmga/data/external_data/{task}/train/images\"\n",
    "TARGET_ANNOTATION_FOLDER = f\"/home/thanh/bmga/data/external_data/{task}/train/annotations\"\n",
    "\n",
    "SOURCE_IMAGE_FOLDER = \"/home/thanh/bmga/data/train/images\"\n",
    "SOURCE_ANNOTATION_FOLDER = \"/home/thanh/bmga/data/train/annotations\"\n",
    "\n",
    "for file in os.listdir(SOURCE_IMAGE_FOLDER):\n",
    "    shutil.copy(os.path.join(SOURCE_IMAGE_FOLDER, file), TARGET_IMAGE_FOLDER)\n",
    "\n",
    "for file in os.listdir(SOURCE_ANNOTATION_FOLDER):\n",
    "    shutil.copy(os.path.join(SOURCE_ANNOTATION_FOLDER, file), TARGET_ANNOTATION_FOLDER)\n",
    "\n",
    "\n",
    "# !cp -r /home/thanh/bmga/data/validation /home/thanh/bmga/data/external_data/all/validation\n",
    "!cp -r /home/thanh/bmga/data/validation /home/thanh/bmga/data/external_data/db/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !cd external_data/chartinfo && \\\n",
    "# #     unzip -qq ICDAR2023_CHARTINFO_IIITH_UB_UNITEC_PMC_TEST_TASK3_v1.0.zip && \\\n",
    "# #     unzip -qq ICDAR2023_CHARTINFO_IIITH_UB_UNITEC_PMC_TEST_v1.0___NO_TASK3.zip && \\\n",
    "# #     unzip -qq ICDAR2023_CHARTINFO_UB_UNITEC_PMC_TRAIN_V1.0.zip\n",
    "\n",
    "# !cd external_data/chartqa && unzip -qq ChartQA\\ Dataset.zip\n",
    "\n",
    "# !cd external_data/dvqa && tar -xzf images.tar.gz && tar -xzf metadata.tar.gz\n",
    "\n",
    "# !cd external_data/figureqa && \\\n",
    "#     tar -xzf figureqa-sample-train-v1.tar.gz && \\\n",
    "#     tar -xzf figureqa-test1-v1.tar.gz && \\\n",
    "#     tar -xzf figureqa-test2-v1.tar.gz && \\\n",
    "#     tar -xzf figureqa-train1-v1.tar.gz && \\\n",
    "#     tar -xzf figureqa-validation1-v1.tar.gz && \\\n",
    "#     tar -xzf figureqa-validation2-v1.tar.gz\n",
    "\n",
    "# !cd external_data/plotqa/Images/Train && tar -xzf png.tar.gz\n",
    "# !cd external_data/plotqa/Images/Test && tar -xzf png.tar.gz\n",
    "# !cd external_data/plotqa/Images/Validation && tar -xzf png.tar.gz"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we should convert the data to the competition format then use the old code to generate the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chartinfo\n",
    "def extract_chartinfo_data(root_annotation_folder, root_image_folder, extracted_annotation_folder, task=\"all\"):\n",
    "    if not os.path.exists(extracted_annotation_folder):\n",
    "        os.makedirs(extracted_annotation_folder)\n",
    "\n",
    "    if task == \"all\":\n",
    "        usable_graph_types = [\"line\", \"scatter\", \"scatter-line\", \"vertical_bar\"] # ignore horizontal_bar because of data issue\n",
    "    elif task == \"db\":\n",
    "        usable_graph_types = [\"area\", \"heatmap\", \"horizontal_bar\", \"line\", \"scatter\", \"scatter-line\", \"vertical_bar\", \"vertical_box\", \"vertical_interval\"]\n",
    "    mapping = {\n",
    "        \"horizontal_bar\": \"horizontal_bar\",\n",
    "        \"line\": \"line\",\n",
    "        \"scatter\": \"scatter\",\n",
    "        \"scatter-line\": \"scatter\",\n",
    "        \"vertical_bar\": \"vertical_bar\"\n",
    "    }\n",
    "\n",
    "    count = 0\n",
    "    total = 0\n",
    "    extracted_image_paths = []\n",
    "\n",
    "    for graph_type in usable_graph_types:\n",
    "        annotation_folder = os.path.join(root_annotation_folder, graph_type)\n",
    "        image_folder = os.path.join(root_image_folder, graph_type)\n",
    "\n",
    "        for annotation_file in tqdm(os.listdir(annotation_folder)):\n",
    "            total += 1\n",
    "            data = json.load(open(os.path.join(annotation_folder, annotation_file)))\n",
    "            # task1 output is graph type\n",
    "            # task2 output is text location\n",
    "            # task3 output is type of text\n",
    "            # task4 output is x/y axis points\n",
    "            # task5 is legends analysis\n",
    "            # task6 output is final outputs\n",
    "            # text data\n",
    "\n",
    "            if data.get(\"task4\") is None:\n",
    "                continue\n",
    "\n",
    "            id_to_role = {\n",
    "                item[\"id\"]: item[\"role\"] for item in data[\"task3\"][\"output\"][\"text_roles\"]\n",
    "            }\n",
    "            text_data = []\n",
    "            for item in data[\"task2\"][\"output\"][\"text_blocks\"]:\n",
    "                item[\"role\"] = id_to_role[item[\"id\"]]\n",
    "                text_data.append(item)\n",
    "\n",
    "            # axes data\n",
    "            axes_data = {\n",
    "                \"x-axis\": {\n",
    "                    \"ticks\": data[\"task4\"][\"output\"][\"axes\"][\"x-axis\"]\n",
    "                },\n",
    "                \"y-axis\": {\n",
    "                    \"ticks\": data[\"task4\"][\"output\"][\"axes\"][\"y-axis\"]\n",
    "                }\n",
    "            }\n",
    "            if graph_type in [\"scatter\", \"scatter-line\"]:\n",
    "                axes_data[\"x-axis\"][\"values-type\"] = \"numerical\"\n",
    "                axes_data[\"y-axis\"][\"values-type\"] = \"numerical\"\n",
    "            elif graph_type in [\"vertical_bar\", \"line\"]:\n",
    "                axes_data[\"x-axis\"][\"values-type\"] = \"categorical\"\n",
    "                axes_data[\"y-axis\"][\"values-type\"] = \"numerical\"\n",
    "            elif graph_type in [\"horizontal_bar\"]:\n",
    "                axes_data[\"x-axis\"][\"values-type\"] = \"numerical\"\n",
    "                axes_data[\"y-axis\"][\"values-type\"] = \"categorical\"\n",
    "            else:\n",
    "                axes_data[\"x-axis\"][\"values-type\"] = \"categorical\"\n",
    "                axes_data[\"y-axis\"][\"values-type\"] = \"categorical\"\n",
    "\n",
    "            if task == \"all\":\n",
    "                if data.get(\"task4\") is not None and data.get(\"task6\") is not None and len(data[\"task6\"][\"output\"][\"data series\"]) == 1:\n",
    "                    image_path = os.path.join(image_folder, os.path.splitext(annotation_file)[0] + \".jpg\")\n",
    "                    count += 1\n",
    "\n",
    "                    data_series = data[\"task6\"][\"output\"][\"data series\"][0][\"data\"]\n",
    "                else:\n",
    "                    continue\n",
    "            elif task == \"db\":\n",
    "                image_path = os.path.join(image_folder, os.path.splitext(annotation_file)[0] + \".jpg\")\n",
    "                count += 1\n",
    "\n",
    "                data_series = []\n",
    "        \n",
    "            extracted_annotation = {\n",
    "                \"source\": \"external\",\n",
    "                \"chart-type\": mapping.get(graph_type, graph_type),\n",
    "                \"text\": text_data,\n",
    "                \"axes\": axes_data,\n",
    "                \"data-series\": data_series,\n",
    "            }\n",
    "            \n",
    "            # save annotation\n",
    "            with open(os.path.join(extracted_annotation_folder, annotation_file), \"w\") as f:\n",
    "                json.dump(extracted_annotation, f, indent=4)\n",
    "\n",
    "            extracted_image_paths.append(image_path)\n",
    "        \n",
    "    print(f\"Extracted {count} images out of {total} images\")\n",
    "\n",
    "    return extracted_image_paths\n",
    "\n",
    "# # training set: \n",
    "root_annotation_folder = \"./external_data/chartinfo/annotations_JSON/\"\n",
    "root_image_folder = \"./external_data/chartinfo/images/\"\n",
    "extracted_annotation_folder = \"./external_data/chartinfo/extracted_annotations_db/\"\n",
    "\n",
    "\n",
    "extracted_image_paths = extract_chartinfo_data(root_annotation_folder, root_image_folder, extracted_annotation_folder, task=task)\n",
    "\n",
    "if task == \"all\":\n",
    "    # write extracted_image_paths to a file\n",
    "    with open(\"./external_data/chartinfo/extracted_image_paths.txt\", \"w\") as f:\n",
    "        for path in extracted_image_paths:\n",
    "            f.write(path + \"\\n\")\n",
    "elif task == \"db\":\n",
    "    # write extracted_image_paths to a file\n",
    "    with open(\"./external_data/chartinfo/extracted_image_paths_db.txt\", \"w\") as f:\n",
    "        for path in extracted_image_paths:\n",
    "            f.write(path + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "\n",
    "# copy to all folder\n",
    "TARGET_IMAGE_FOLDER = f\"/home/thanh/bmga/data/external_data/{task}/train/images\"\n",
    "TARGET_ANNOTATION_FOLDER = f\"/home/thanh/bmga/data/external_data/{task}/train/annotations\"\n",
    "\n",
    "if not os.path.exists(TARGET_IMAGE_FOLDER):\n",
    "    os.makedirs(TARGET_IMAGE_FOLDER)\n",
    "\n",
    "if not os.path.exists(TARGET_ANNOTATION_FOLDER):\n",
    "    os.makedirs(TARGET_ANNOTATION_FOLDER)\n",
    "\n",
    "for path in tqdm(extracted_image_paths):\n",
    "    shutil.copy2(path, TARGET_IMAGE_FOLDER)\n",
    "\n",
    "for file in tqdm(os.listdir(extracted_annotation_folder)):\n",
    "    shutil.copy2(os.path.join(extracted_annotation_folder, file), TARGET_ANNOTATION_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # test set: doesn't have final outputs\n",
    "# root_test_folder = \"./external_data/chartinfo/ICDAR2023_CHARTINFO_IIIT_UB_UNITEC_PMC_TEST_v1.0/\"\n",
    "# test_extracted_image_paths = []\n",
    "\n",
    "# for folder in os.listdir(root_test_folder):\n",
    "#     root_annotation_folder = os.path.join(root_test_folder, folder, \"annotations\")\n",
    "#     root_image_folder = os.path.join(root_test_folder, folder, \"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FigureQA: generated locally\n",
    "annotation_folder = \"/home/thanh/bmga/data/FigureQA/bmga_generation/figureqa-train1/train1_1/figure_data/json_annotations\"\n",
    "image_folder = \"/home/thanh/bmga/data/FigureQA/bmga_generation/figureqa-train1/train1_1/figure_data/png\"\n",
    "extracted_annotation_folder = \"/home/thanh/bmga/data/FigureQA/bmga_final/figureqa-train1/extracted_annotations/\"\n",
    "\n",
    "if not os.path.exists(extracted_annotation_folder):\n",
    "    os.makedirs(extracted_annotation_folder)\n",
    "\n",
    "mapping = {\n",
    "    \"dot_line\": \"scatter\",\n",
    "    \"hbar_categorical\": \"horizontal_bar\",\n",
    "    \"line\": \"line\",\n",
    "    \"pie\": \"pie\",\n",
    "    \"vbar_categorical\": \"vertical_bar\"\n",
    "}\n",
    "\n",
    "# find all annotation - image pairs\n",
    "annotation_path_dict = {}\n",
    "for annotation_file in os.listdir(annotation_folder):\n",
    "    annotation_path_dict[annotation_file.split(\"_annotations.\")[0]] = os.path.join(annotation_folder, annotation_file)\n",
    "\n",
    "image_path_dict = {}\n",
    "for image_file in os.listdir(image_folder):\n",
    "    image_path_dict[image_file.split(\".\")[0]] = os.path.join(image_folder, image_file)\n",
    "\n",
    "intersection = set(annotation_path_dict.keys()).intersection(set(image_path_dict.keys()))\n",
    "print(f\"Found {len(intersection)} annotation - image pairs\")\n",
    "\n",
    "image_annotation_pairs = []\n",
    "for key in intersection:\n",
    "    image_annotation_pairs.append((image_path_dict[key], annotation_path_dict[key]))\n",
    "\n",
    "# with open(annotation_path, \"r\") as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# TODO: map the points correspond to the labels in the line graph instead of all the points\n",
    "extracted_image_paths = []\n",
    "# for item in tqdm(data):\n",
    "for image_path, annotation_path in tqdm(image_annotation_pairs):\n",
    "    with open(annotation_path, \"r\") as f:\n",
    "        item = json.load(f)\n",
    "    text_data = []\n",
    "\n",
    "    graph_type = mapping[item[\"type\"]]\n",
    "    \n",
    "    x_id_to_value = {}\n",
    "    y_id_to_value = {}\n",
    "    x_id_to_pixel = {}\n",
    "    y_id_to_pixel = {}\n",
    "\n",
    "    x_major_label = item[\"general_figure_info\"][\"x_axis\"][\"major_labels\"]\n",
    "    num_x_labels = len(x_major_label[\"bboxes\"]) // 2\n",
    "    for i in range(num_x_labels):\n",
    "        box, value = x_major_label[\"bboxes\"][i], x_major_label[\"values\"][i]\n",
    "        x, y, w, h = int(box[\"x\"]), int(box[\"y\"]), int(box[\"w\"]), int(box[\"h\"])\n",
    "\n",
    "        text_data.append({\n",
    "            \"id\": i,\n",
    "            \"polygon\": {\n",
    "                \"x0\": x,\n",
    "                \"y0\": y,\n",
    "                \"x1\": x + w,\n",
    "                \"y1\": y,\n",
    "                \"x2\": x + w,\n",
    "                \"y2\": y + h,\n",
    "                \"x3\": x,\n",
    "                \"y3\": y + h\n",
    "            },\n",
    "            \"text\": value,\n",
    "            \"role\": \"tick_label\"\n",
    "        })\n",
    "        x_id_to_value[i] = value\n",
    "\n",
    "    y_major_label = item[\"general_figure_info\"][\"y_axis\"][\"major_labels\"]\n",
    "    num_y_labels = len(y_major_label[\"bboxes\"]) // 2\n",
    "    for i in range(num_y_labels):\n",
    "        box, value = y_major_label[\"bboxes\"][i], y_major_label[\"values\"][i]\n",
    "        x, y, w, h = int(box[\"x\"]), int(box[\"y\"]), int(box[\"w\"]), int(box[\"h\"])\n",
    "\n",
    "        text_data.append({\n",
    "            \"id\": num_x_labels + i,\n",
    "            \"polygon\": {\n",
    "                \"x0\": x,\n",
    "                \"y0\": y,\n",
    "                \"x1\": x + w,\n",
    "                \"y1\": y,\n",
    "                \"x2\": x + w,\n",
    "                \"y2\": y + h,\n",
    "                \"x3\": x,\n",
    "                \"y3\": y + h\n",
    "            },\n",
    "            \"text\": value,\n",
    "            \"role\": \"tick_label\"\n",
    "        })\n",
    "        y_id_to_value[num_x_labels + i] = value\n",
    "\n",
    "    axes_data = {}\n",
    "\n",
    "    x_ticks = item[\"general_figure_info\"][\"x_axis\"][\"major_ticks\"]\n",
    "    num_x_ticks = len(x_ticks[\"bboxes\"]) // 2\n",
    "\n",
    "    x_axes_data = []\n",
    "    for i in range(num_x_ticks):\n",
    "        box = x_ticks[\"bboxes\"][i]\n",
    "        x, y, w, h = box[\"x\"], box[\"y\"], box[\"w\"], box[\"h\"]\n",
    "\n",
    "        x_axes_data.append({\n",
    "            \"id\": i,\n",
    "            \"tick_pt\": {\n",
    "                \"x\": x + w // 2,\n",
    "                \"y\": int(y + h // 4)\n",
    "            }\n",
    "        })\n",
    "        x_id_to_pixel[i] = x + w // 2\n",
    "\n",
    "    axes_data[\"x-axis\"] = {\n",
    "        \"ticks\": x_axes_data,\n",
    "        \"values-type\": \"categorical\" if graph_type in [\"vertical_bar\", \"line\"] else \"numerical\"  # horizontal_bar, scatter\n",
    "    }\n",
    "\n",
    "    y_ticks = item[\"general_figure_info\"][\"y_axis\"][\"major_ticks\"]\n",
    "    num_y_ticks = len(y_ticks[\"bboxes\"]) // 2\n",
    "\n",
    "    y_axes_data = []\n",
    "    for i in range(num_y_ticks):\n",
    "        box = y_ticks[\"bboxes\"][i]\n",
    "        x, y, w, h = box[\"x\"], box[\"y\"], box[\"w\"], box[\"h\"]\n",
    "\n",
    "        y_axes_data.append({\n",
    "            \"id\": num_x_ticks + i,\n",
    "            \"tick_pt\": {\n",
    "                \"x\": int(x + 3 * w // 4),\n",
    "                \"y\": y + h // 2\n",
    "            }\n",
    "        })\n",
    "        y_id_to_pixel[num_x_ticks + i] = y + h // 2\n",
    "\n",
    "    axes_data[\"y-axis\"] = {\n",
    "        \"ticks\": y_axes_data,\n",
    "        \"values-type\": \"categorical\" if graph_type in [\"horizontal_bar\"] else \"numerical\"  # vertical_bar, scatter, line\n",
    "    }\n",
    "\n",
    "    if graph_type != \"line\":\n",
    "        data_series = [\n",
    "            {\n",
    "                \"x\": x,\n",
    "                \"y\": y,\n",
    "            } for x, y in zip(item[\"models\"][0][\"x\"], item[\"models\"][0][\"y\"])\n",
    "        ]\n",
    "    else:  # TODO: for line data\n",
    "        x_value_to_pixel = {}\n",
    "        for x_id, x_value in x_id_to_value.items():\n",
    "            x_value_to_pixel[x_value] = x_id_to_pixel[x_id]\n",
    "\n",
    "        y_value_to_pixel = {}\n",
    "        for y_id, y_value in y_id_to_value.items():\n",
    "            y_value_to_pixel[y_value] = y_id_to_pixel[y_id]\n",
    "\n",
    "        # draw the line in data series then select the values on x labels\n",
    "        xys = [(x, y) for x, y in zip(item[\"models\"][0][\"x\"], item[\"models\"][0][\"y\"])]\n",
    "        xys.sort(key=lambda x: x[0])\n",
    "\n",
    "        data_series = []\n",
    "        for x_value in x_id_to_value.values():\n",
    "            # find the closest 2 points which have to the x_value in xys\n",
    "            p1, p2 = sorted(xys, key=lambda x: abs(int(x[0]) - int(x_value)))[:2]\n",
    "\n",
    "            x1, y1 = p1\n",
    "            x2, y2 = p2\n",
    "\n",
    "            # calculate the y_value\n",
    "            y_value = (y2 - y1) / (x2 - x1) * (int(x_value) - x1) + y1\n",
    "\n",
    "            data_series.append({\n",
    "                \"x\": x_value,\n",
    "                \"y\": y_value,\n",
    "            })\n",
    "\n",
    "\n",
    "    extracted_annotation = {\n",
    "        \"source\": \"external\",\n",
    "        \"chart-type\": graph_type,\n",
    "        \"text\": text_data,\n",
    "        \"axes\": axes_data,\n",
    "        \"data-series\": data_series,\n",
    "    }\n",
    "\n",
    "    # save annotation\n",
    "    # annotation_file = str(item[\"image_index\"]) + \".json\"\n",
    "    annotation_file = os.path.basename(annotation_path).split(\"_annotations.\")[0] + \".json\"\n",
    "    with open(os.path.join(extracted_annotation_folder, annotation_file), \"w\") as f:\n",
    "        json.dump(extracted_annotation, f, indent=4)\n",
    "\n",
    "    # image_path = os.path.join(image_folder, str(item[\"image_index\"]) + \".png\")\n",
    "    extracted_image_paths.append(image_path)\n",
    "\n",
    "    # if graph_type == \"line\":\n",
    "    #     break\n",
    "\n",
    "\n",
    "# write extracted_image_paths to a file\n",
    "with open(\"/home/thanh/bmga/data/FigureQA/bmga_generation/figureqa-train1/train1_1/figure_data/extracted_image_paths.txt\", \"w\") as f:\n",
    "    for path in extracted_image_paths:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "\n",
    "# copy to all folder\n",
    "TARGET_IMAGE_FOLDER = f\"/home/thanh/bmga/data/external_data/{task}/train/images\"\n",
    "TARGET_ANNOTATION_FOLDER = f\"/home/thanh/bmga/data/external_data/{task}/train/annotations\"\n",
    "\n",
    "for path in tqdm(extracted_image_paths):\n",
    "    shutil.copy2(path, TARGET_IMAGE_FOLDER)\n",
    "\n",
    "for file in tqdm(os.listdir(extracted_annotation_folder)):\n",
    "    shutil.copy2(os.path.join(extracted_annotation_folder, file), TARGET_ANNOTATION_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# image = cv2.imread(image_path)\n",
    "\n",
    "# # visualize data_series\n",
    "# for data_point in data_series:\n",
    "#     # print(x, y)\n",
    "#     x, y = data_point[\"x\"], data_point[\"y\"]\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "# # figure size \n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.imshow(image)\n",
    "# data_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # chartqa # doesn't have text for y_labels and ticks information, so we can only use x_labels, final outputs -> maybe for test set and Donut\n",
    "# root_annotation_folder = \"./external_data/chartqa/ChartQA Dataset/train/annotations\"\n",
    "# root_image_folder = \"./external_data/chartqa/ChartQA Dataset/train/png\"\n",
    "# extracted_annotation_folder = \"./external_data/chartqa/ChartQA Dataset/extracted_annotations/\"\n",
    "\n",
    "# if not os.path.exists(extracted_annotation_folder):\n",
    "#     os.makedirs(extracted_annotation_folder)\n",
    "\n",
    "# mapping = {\n",
    "#     \"hbar\": \"horizontal_bar\",\n",
    "#     \"line\": \"line\",\n",
    "#     \"vbar\": \"vertical_bar\",\n",
    "# }\n",
    "\n",
    "# count = 0\n",
    "# total = 0\n",
    "# graph_types = set()\n",
    "# for annotation_file in tqdm(os.listdir(root_annotation_folder)):\n",
    "#     with open(os.path.join(root_annotation_folder, annotation_file)) as f:\n",
    "#         data = json.load(f)\n",
    "\n",
    "#     graph_types.add(data[\"type\"])\n",
    "\n",
    "#     total += 1\n",
    "\n",
    "#     if len(data[\"models\"]) == 1 and data[\"type\"] in mapping:\n",
    "#         count += 1\n",
    "#         image_path = os.path.join(root_image_folder, annotation_file.split(\".\")[0] + \".png\")\n",
    "#         extracted_annotation = {\n",
    "#             \"source\": \"external\",\n",
    "#         }\n",
    "\n",
    "#         break\n",
    "\n",
    "# data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dvqa: only have boxes for x_labels, y_labels, final info -> can only be used for DB model, Donut\n",
    "# train_annotation_path = \"./external_data/dvqa/metadata/train_metadata.json\"\n",
    "# val_easy_annotation_path = \"./external_data/dvqa/metadata/val_easy_metadata.json\"\n",
    "# val_hard_annotation_path = \"./external_data/dvqa/metadata/val_hard_metadata.json\"\n",
    "\n",
    "# train_image_folder = \"./external_data/dvqa/images/\"\n",
    "\n",
    "# extracted_annotation_folder = \"./external_data/dvqa/extracted_annotations/\"\n",
    "\n",
    "# if not os.path.exists(extracted_annotation_folder):\n",
    "#     os.makedirs(extracted_annotation_folder)\n",
    "\n",
    "# mapping = {}\n",
    "\n",
    "# count = 0\n",
    "# total = 0\n",
    "# extracted_image_paths = []\n",
    "\n",
    "# with open(train_annotation_path, \"r\") as f:\n",
    "#     train_data = json.load(f)\n",
    "# # visualize one sample image\n",
    "# # all_image_paths = [os.path.join(train_image_folder, image_name) for image_name in os.listdir(train_image_folder) ]\n",
    "# image_path = all_image_paths[1123]\n",
    "# Image.open(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # figureqa # all synthetic from here: https://github.com/Maluuba/FigureQA\n",
    "# annotation_path = \"/home/thanh/bmga/data/external_data/figureqa/train1/annotations.json\"\n",
    "# image_folder = \"/home/thanh/bmga/data/external_data/figureqa/train1/png/\"\n",
    "# extracted_annotation_folder = \"/home/thanh/bmga/data/external_data/figureqa/train1/extracted_annotations/\"\n",
    "\n",
    "# if not os.path.exists(extracted_annotation_folder):\n",
    "#     os.makedirs(extracted_annotation_folder)\n",
    "\n",
    "# # {'dot_line', 'hbar_categorical', 'line', 'pie', 'vbar_categorical'}\n",
    "# # mapping = {\n",
    "# #     \"dot_line\": \"line\",\n",
    "\n",
    "\n",
    "# with open(annotation_path, \"r\") as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# image_path = os.path.join(image_folder, str(data[0][\"image_index\"]) + \".png\")\n",
    "# Image.open(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plotqa: seems like all synthetic\n",
    "# annotation_path = \"./external_data/plotqa/Annotations/Train/annotations.json\"\n",
    "# image_folder = \"./external_data/plotqa/Images/Train/png\"\n",
    "\n",
    "# with open(annotation_path, \"r\") as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# image_path = os.path.join(image_folder, str(150000) + \".png\")\n",
    "# Image.open(image_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X/Y labels detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can take all data from chartinfo without filtering, also data in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text recognition - parseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "IMAGE_FOLDER = \"./train/images\"\n",
    "ANNOTATION_FOLDER = \"./train/annotations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "\n",
    "i = 0\n",
    "# i += 1\n",
    "annotation_files = os.listdir(ANNOTATION_FOLDER)\n",
    "while i < len(annotation_files):\n",
    "    annotation_file = annotation_files[i]\n",
    "    with open(os.path.join(ANNOTATION_FOLDER, annotation_file), \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    if data[\"chart-type\"] != \"scatter\" or data[\"source\"] == \"generated\":\n",
    "        i += 1\n",
    "        continue\n",
    "\n",
    "    points = data[\"visual-elements\"][\"scatter points\"][0]\n",
    "    image_name = annotation_file.split(\".\")[0] + \".jpg\"\n",
    "\n",
    "    # visualize points on image\n",
    "    image_path = os.path.join(IMAGE_FOLDER, image_name)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    for point in points:\n",
    "        x, y = int(point[\"x\"]), int(point[\"y\"])\n",
    "        cv2.circle(image, (x, y), 3, (0, 0, 255), -1)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to coco format\n",
    "annotation_files = os.listdir(ANNOTATION_FOLDER)\n",
    "\n",
    "# split train val based on train_image_names\n",
    "train_annotation_files = []\n",
    "val_annotation_files = []\n",
    "\n",
    "for file in annotation_files:\n",
    "    image_name = file.split(\".\")[0] + \".jpg\"\n",
    "    if image_name in train_file_names:\n",
    "        train_annotation_files.append(file)\n",
    "    else:\n",
    "        val_annotation_files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_annotation_files), len(val_annotation_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_coco_format(annotation_files):\n",
    "    i = 0\n",
    "    image_index = 0\n",
    "\n",
    "    images = []\n",
    "    annotations = []\n",
    "\n",
    "    while i < len(annotation_files):\n",
    "        annotation_file = annotation_files[i]\n",
    "        with open(os.path.join(ANNOTATION_FOLDER, annotation_file), \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        if data[\"chart-type\"] != \"scatter\":\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        points = data[\"visual-elements\"][\"scatter points\"][0]\n",
    "        image_name = annotation_file.split(\".\")[0] + \".jpg\"\n",
    "\n",
    "        # visualize points on image\n",
    "        image_path = os.path.join(IMAGE_FOLDER, image_name)\n",
    "        img = cv2.imread(image_path)\n",
    "\n",
    "        images.append({\n",
    "            \"id\": image_index,\n",
    "            \"file_name\": image_name,\n",
    "            \"width\": img.shape[1],\n",
    "            \"height\": img.shape[0],\n",
    "        })\n",
    "\n",
    "        size = 12\n",
    "        box_height = box_width = min(int(size / 640 * img.shape[0]), int(size / 640 * img.shape[1]))\n",
    "\n",
    "        for point in points:\n",
    "            x, y = int(point[\"x\"]), int(point[\"y\"])\n",
    "            bbox = [x - box_width // 2, y - box_height // 2, box_width, box_height]\n",
    "            annotations.append({\n",
    "                \"id\": len(annotations),\n",
    "                \"image_id\": image_index,\n",
    "                \"category_id\": 1,\n",
    "                \"bbox\": bbox,\n",
    "                \"iscrowd\": 0,\n",
    "                \"area\": 100,\n",
    "            })\n",
    "\n",
    "        image_index += 1\n",
    "        i += 1\n",
    "\n",
    "    coco_annotations = {\n",
    "        \"images\": images,\n",
    "        \"annotations\": annotations,\n",
    "        \"categories\": [\n",
    "            {\n",
    "                \"id\": 1,\n",
    "                \"name\": \"value\",\n",
    "                \"supercategory\": \"value\",\n",
    "            },\n",
    "            {\n",
    "                \"id\": 2,\n",
    "                \"name\": \"x\",\n",
    "                \"supercategory\": \"x\",\n",
    "            },\n",
    "            {\n",
    "                \"id\": 3,\n",
    "                \"name\": \"y\",\n",
    "                \"supercategory\": \"y\",\n",
    "            },\n",
    "        ],\n",
    "        \"type\": \"instances\",\n",
    "    }\n",
    "\n",
    "    return coco_annotations\n",
    "\n",
    "\n",
    "train_coco_annotations = convert_to_coco_format(train_annotation_files)\n",
    "val_coco_annotations = convert_to_coco_format(val_annotation_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_folder_name = \"new_scatter_annotations\"\n",
    "\n",
    "if not os.path.exists(os.path.join(ROOT_DATA_FOLDER, annotation_folder_name)):\n",
    "    os.makedirs(os.path.join(ROOT_DATA_FOLDER, annotation_folder_name))\n",
    "\n",
    "# save to json\n",
    "with open(os.path.join(ROOT_DATA_FOLDER, f\"{annotation_folder_name}/train_coco_annotations.json\"), \"w\") as writer:\n",
    "    json.dump(train_coco_annotations, writer)\n",
    "\n",
    "with open(os.path.join(ROOT_DATA_FOLDER, f\"{annotation_folder_name}/val_coco_annotations.json\"), \"w\") as writer:\n",
    "    json.dump(val_coco_annotations, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54ee78448139da1fc988a284c08f20c10612988b148a370999f707fbbae2b5fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
